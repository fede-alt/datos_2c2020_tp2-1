{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = [\n",
    "                'Account_Created_Date', 'Opportunity_Created_Date',\n",
    "                'Quote_Expiry_Date', 'Last_Modified_Date',\n",
    "                'Planned_Delivery_Start_Date','Planned_Delivery_End_Date',\n",
    "                ]\n",
    "\n",
    "categorical_columns = [\n",
    "        'Region', 'Territory', 'Bureaucratic_Code',\n",
    "        'Source ', 'Billing_Country', 'Account_Name',\n",
    "        'Opportunity_Name', 'Account_Owner', 'Opportunity_Owner',\n",
    "        'Account_Type', 'Opportunity_Type', 'Quote_Type',\n",
    "        'Delivery_Terms', 'Brand', 'Product_Type',\n",
    "        'Size', 'Product_Category_B', 'Currency',\n",
    "        'Last_Modified_By', 'Product_Family', 'Product_Name',\n",
    "        'ASP_Currency', 'ASP_(converted)_Currency', 'Delivery_Quarter',\n",
    "        'Total_Amount_Currency', 'Total_Taxable_Amount_Currency', 'Stage',\n",
    "        'Prod_Category_A'\n",
    "    ]\n",
    "\n",
    "# Columnnas excluidas porque tienen igual valor en todos sus registros\n",
    "empty = ['Actual_Delivery_Date', 'Last_Activity',\n",
    "        'Submitted_for_Approval','Prod_Category_A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def open_and_filter(dataset):\n",
    "    \n",
    "    column_types = { col:'category' for col in categorical_columns }\n",
    "    \n",
    "\n",
    "    \n",
    "    # read_csv\n",
    "    df = pd.read_csv(dataset, parse_dates=date_columns, dtype=column_types,\n",
    "                     index_col='ID', na_values=['Other', 'NaT', 'None'],\n",
    "                     usecols=lambda x: x not in empty)\n",
    "    \n",
    "    # Re-typing\n",
    "    df['Sales_Contract_No'] = df['Sales_Contract_No'].fillna(0).astype(np.int64)\n",
    "    df['Month'] = pd.to_datetime(df['Month'], format='%Y - %m')\n",
    "    \n",
    "    # Agruping regions \n",
    "    df.loc[((df.Region == \"EMEA\")&(df.Territory.str.contains(\"America\"))), \"Region\"] = \"Americas\"\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesamiento de los datos\n",
    "\n",
    "El objetivo de esta etapa, es recibir los datos \"crudos\" y realizar procedimientos necesarios para filtrar features de poco valor y crear otros features que revelen información de importancia, para que los modelos de machine learning que luego los utilizarán en una etapa posterior, puedan ralizar un predicción mas precisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = open_and_filter(\"rawdata/Train_TP2_Datos_2020-2C.csv\")\n",
    "df2 = open_and_filter(\"rawdata/Test_TP2_Datos_2020-2C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set has 16947 elements and 47 features\n",
      "The train set has 2551 elements and 46 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The train set has {df1.shape[0]} elements and {df1.shape[1]} features\")\n",
    "print(f\"The train set has {df2.shape[0]} elements and {df2.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Territory                    0.294978\n",
       "Source                       0.560394\n",
       "Billing_Country              0.001593\n",
       "Account_Type                 0.006609\n",
       "Brand                        0.974686\n",
       "Product_Type                 0.970673\n",
       "Size                         0.965422\n",
       "Product_Category_B           0.970732\n",
       "Price                        0.978993\n",
       "Currency                     0.947188\n",
       "Quote_Expiry_Date            0.272910\n",
       "ASP                          0.189355\n",
       "ASP_(converted)              0.189355\n",
       "Planned_Delivery_End_Date    0.004426\n",
       "Total_Amount                 0.003481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypotesis: the features that contains more than 75% of NaN values \n",
    "#            do not contribute sustancial inforation\n",
    "na_values_rate = df1.isna().sum()/len(df1)\n",
    "na_values_rate = na_values_rate[na_values_rate>0]\n",
    "na_values_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns 'Brand', 'Product_Type', 'Size', 'Product_Category_B', 'Price', 'Currency' dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop\n",
    "to_drop = na_values_rate[na_values_rate > 0.75].index.to_list()\n",
    "\n",
    "trainset = df1.drop(columns = to_drop)\n",
    "testset = df2.drop(columns= to_drop)\n",
    "\n",
    "text = \"', '\".join(to_drop)\n",
    "print(f\"Columns '{text}' dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este modelo entonce no se consideraran las columnas ``'Brand'``, ``'Product_Type'``, ``'Size'``, ``'Product_Category_B'``, ``'Price'``, ``'Currency'``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Territory                    0.294978\n",
       "Source                       0.560394\n",
       "Billing_Country              0.001593\n",
       "Account_Type                 0.006609\n",
       "Quote_Expiry_Date            0.272910\n",
       "ASP                          0.189355\n",
       "ASP_(converted)              0.189355\n",
       "Planned_Delivery_End_Date    0.004426\n",
       "Total_Amount                 0.003481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El resto de columnas con NA_Values\n",
    "contains_na = na_values_rate[na_values_rate <= 0.75].index.to_list()\n",
    "na_values_rate[contains_na]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_fill_na(df,columns):\n",
    "\n",
    "    result = df.copy()\n",
    "    dtypes = result[columns].dtypes\n",
    "    cat = dtypes[dtypes == \"category\"].index.to_list()\n",
    "    not_cat = dtypes[dtypes != \"category\"].index.to_list()\n",
    "    \n",
    "    for col in cat:\n",
    "        if \"Other\" not in result[col].cat.categories:\n",
    "            result[col].cat.add_categories(\"Other\",inplace=True)\n",
    "        result[col].fillna(\"Other\",inplace= True)\n",
    "    \n",
    "    for col in not_cat:\n",
    "        result[col].fillna(result[col].mean(),inplace= True)\n",
    "\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = my_fill_na(trainset,contains_na)\n",
    "testset = my_fill_na(testset,contains_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restan valores nulos en trainset: False\n",
      "Restan valores nulos en testset: False\n"
     ]
    }
   ],
   "source": [
    "na_train = trainset.isna().sum() > 0\n",
    "na_test = testset.isna().sum() > 0\n",
    "\n",
    "print(f\"Restan valores nulos en trainset: {na_train.any()}\")\n",
    "print(f\"Restan valores nulos en testset: {na_test.any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya filtramos las features con excesivos Nan values y rellenamos aquellas que su procentage de nan values es moderado, con valores predeterminados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del target de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stage</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27761</th>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27760</th>\n",
       "      <td>Closed Won</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27446</th>\n",
       "      <td>Closed Won</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16808</th>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16805</th>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16802</th>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27455</th>\n",
       "      <td>Closed Won</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24353</th>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Stage  target\n",
       "ID                        \n",
       "27761  Closed Lost       0\n",
       "27760   Closed Won       1\n",
       "27446   Closed Won       1\n",
       "16808  Closed Lost       0\n",
       "16805  Closed Lost       0\n",
       "16802  Closed Lost       0\n",
       "16799  Closed Lost       0\n",
       "27455   Closed Won       1\n",
       "24353  Closed Lost       0\n",
       "24355  Closed Lost       0"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[\"target\"] = (trainset[\"Stage\"] == \"Closed Won\").astype(int)\n",
    "trainset[[\"Stage\",\"target\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de valores categóricos\n",
    "\n",
    "En esta sección, lo que vamos a hacer es buscar valores categóricos de los features del set de datos de prueba que no hayan sido contemplados en el set de entrenamiento, que por lo consiguiente, el modelo de machine learning los va a desconocer.\n",
    "\n",
    "Una vez identificados, los reemplazaremos con un valor genérico para \"otros valores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Andorra', 'Finland', 'Mongolia'}"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_A = set(testset[\"Territory\"].value_counts().index)\n",
    "set_B = set(trainset[\"Territory\"].value_counts().index)\n",
    "for value in set_B: set_A.discard(value)\n",
    "set_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1', 'Q2', 'Q3', 'Q4']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Q1', 'Q2', 'Q3', 'Q4']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "official_values = trainset[\"Delivery_Quarter\"].cat.categories.to_list()\n",
    "test_values = testset[\"Delivery_Quarter\"].cat.categories.to_list()\n",
    "display(official_values)\n",
    "display(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = empty+to_drop+[\"Stage\",\"Opportunity_Name\"]\n",
    "results = []\n",
    "for column in categorical_columns:\n",
    "    if column in excluded: continue\n",
    "    \n",
    "    official_values = trainset[column].cat.categories.to_list()\n",
    "    test_values = testset[column].cat.categories.to_list()\n",
    "    \n",
    "    other_values = set(test_values)\n",
    "    for value in official_values: other_values.discard(value)\n",
    "    \n",
    "    if len(other_values)>0:\n",
    "        \n",
    "        if not \"Other\" in testset[column].cat.categories.to_list():\n",
    "            testset[column].cat.add_categories(\"Other\",inplace=True)\n",
    "        \n",
    "        if not \"Other\" in trainset[column].cat.categories.to_list():\n",
    "            trainset[column].cat.add_categories(\"Other\",inplace=True)\n",
    "            \n",
    "        testset[column].replace({x:\"Other\" for x in other_values},inplace=True)\n",
    "    \n",
    "        results.append((column,len(other_values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>discarted values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Territory</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Billing_Country</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Account_Name</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Opportunity_Owner</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last_Modified_By</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Product_Family</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Product_Name</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  discarted values\n",
       "0          Territory                 3\n",
       "1    Billing_Country                 3\n",
       "2       Account_Name               205\n",
       "3  Opportunity_Owner                 5\n",
       "4   Last_Modified_By                 8\n",
       "5     Product_Family                20\n",
       "6       Product_Name                50"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_df = pd.DataFrame(results,columns= [\"column\", \"discarted values\"])\n",
    "others_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      7.00\n",
       "mean      42.00\n",
       "std       73.81\n",
       "min        3.00\n",
       "25%        4.00\n",
       "50%        8.00\n",
       "75%       35.00\n",
       "max      205.00\n",
       "Name: discarted values, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total test values discarted 294, %0.3 of total test data\n"
     ]
    }
   ],
   "source": [
    "display(round(others_df[\"discarted values\"].describe(),2))\n",
    "print(f\"\\nTotal test values discarted {others_df['discarted values'].sum()}, \",end=\"\")\n",
    "print(f\"%{100*round(others_df['discarted values'].sum()/testset.size,3)} of total test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información descartada es muy poca con respecto al volumen del set. Más adelante veremos si es posible extraer información de esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding \n",
    "Realizaremos un dataset básico para poder correr el modelo por primera vez y observar los resultados.\n",
    "Luego realizaremos mejoras e ingeniería de features para ver como se comporta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El set de entrenamiento tiene 711774 elementos\n",
      "El set de test tiene 102040 elementos\n"
     ]
    }
   ],
   "source": [
    "print(f\"El set de entrenamiento tiene {trainset.size} elementos\")\n",
    "print(f\"El set de test tiene {testset.size} elementos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features categóricos a encodear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Delivery_Quarter',\n",
       " 'ASP_Currency',\n",
       " 'Account_Owner',\n",
       " 'Region',\n",
       " 'Billing_Country',\n",
       " 'Opportunity_Owner',\n",
       " 'Product_Name',\n",
       " 'Product_Family',\n",
       " 'Quote_Type',\n",
       " 'Territory',\n",
       " 'Account_Type',\n",
       " 'Source ',\n",
       " 'ASP_(converted)_Currency',\n",
       " 'Opportunity_Type',\n",
       " 'Bureaucratic_Code',\n",
       " 'Delivery_Terms',\n",
       " 'Account_Name',\n",
       " 'Last_Modified_By',\n",
       " 'Total_Taxable_Amount_Currency',\n",
       " 'Total_Amount_Currency']"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded = empty+to_drop\n",
    "excluded.append(\"Opportunity_Name\")\n",
    "excluded.append(\"Stage\")\n",
    "excluded.append(\"target\")\n",
    "toEncode = set([col if col not in excluded else \"\" for col in categorical_columns])\n",
    "toEncode.discard(\"\")\n",
    "toEncode = list(toEncode)\n",
    "\n",
    "print(\"Features categóricos a encodear\")\n",
    "toEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (16947, 2718)\n",
      "Size: 46061946\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16947 entries, 0 to 16946\n",
      "Columns: 2718 entries, 0 to 2717\n",
      "dtypes: float64(2718)\n",
      "memory usage: 351.4 MB\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(drop='if_binary')\n",
    "enc.fit(trainset[toEncode])\n",
    "ohed = pd.DataFrame(enc.transform(trainset[toEncode]).toarray())\n",
    "print(f\"Shape: {ohed.shape}\")\n",
    "print(f\"Size: {ohed.size}\")\n",
    "ohed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos abandonar esta propuesta debido a la poca escalabilidad que tiene este método. Debido a las numerosas columnas categóricas con numerosos valores posibles cada una, necesitamos un total de ``2.723`` columnas para `16.947` entradas, lo cual nos deja un total de `46.146.681` valores en nuestra tabla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary encoding \n",
    "\n",
    "Este método nos permite encodear las features categóricas reduciendo considerablemente el dataset. Si suponemos que los 16.947 valores categóricos posibles se distribuyen uniformemente en las 7 columnas, entonces necesitaremos ``⌊log_2(16.947/7)⌋ + 1  = 9`` columnas nuevas por cada columna categórica original del dataset. En total ``9*7 = 63`` una propuesta cuestionable pero mucho mejor que la anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BinaryEncoding():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__encodings = {}\n",
    "        \n",
    "    def __make_encoding(self,name,categories):\n",
    "\n",
    "        encoding = {}\n",
    "        n_cols = int(math.log(len(categories),2))+1\n",
    "        cols_names = [ name+\"_\"+str(x) for x in range(n_cols) ]\n",
    "\n",
    "        for i in range(len(categories)):\n",
    "            encoding[categories[i]] = list(f'{bin(i)[2:]}'.zfill(n_cols))\n",
    "\n",
    "        return (encoding,cols_names)\n",
    "    \n",
    "    def encode_Series(self, serie, name,verbose=False):\n",
    "        \n",
    "        \n",
    "        if not name in self.__encodings:\n",
    "\n",
    "            categories = serie.cat.categories.to_list()\n",
    "            self.__encodings[name] =  self.__make_encoding(name,categories)\n",
    "        \n",
    "        encoding,cols_names = self.__encodings[name]\n",
    "        data = []\n",
    "        indexs = []\n",
    "        \n",
    "        for index, value in serie.items():\n",
    "\n",
    "            data.append(encoding[value])\n",
    "            indexs.append(index)\n",
    "\n",
    "        df_result = pd.DataFrame(data,columns=cols_names,index=indexs)\n",
    "        return df_result,cols_names\n",
    "    \n",
    "    def getEncoding(self):\n",
    "        return self.__encodings\n",
    "    \n",
    "    def encode_DataFrame(self, df, toEncode, verbose = False):\n",
    "\n",
    "        full_encoded,columns = self.encode_Series(df[toEncode[0]],toEncode[0],verbose)\n",
    "       \n",
    "        for col in toEncode[1:]:\n",
    "            \n",
    "            encoding,col_names = self.encode_Series(df[col],col,verbose)\n",
    "            full_encoded[col_names] = encoding\n",
    "\n",
    "        if verbose: evaluate_encoding(df[toEncode],full_encoded)\n",
    "\n",
    "        return full_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def encode_serie(serie,name):\n",
    "    \n",
    "    encoding = {}\n",
    "    categories = serie.cat.categories.to_list()\n",
    "    n_cols = int(math.log(len(categories),2))+1\n",
    "    cols_names = [ name+\"_\"+str(x) for x in range(n_cols) ]\n",
    "\n",
    "    for i in range(len(categories)):\n",
    "        encoding[categories[i]] = list(f'{bin(i)[2:]}'.zfill(n_cols))\n",
    "    \n",
    "    data = []\n",
    "    indexs = []\n",
    "    \n",
    "    for index, value in serie.items():\n",
    "        data.append(encoding[value])\n",
    "        indexs.append(index)\n",
    "        \n",
    "    df_result = pd.DataFrame(data,columns=cols_names,index=indexs)\n",
    "    return df_result, cols_names\n",
    "\"\"\"\n",
    "[]+[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_encoding(original,encoded):\n",
    "\n",
    "    # Recuento de cada una de las combinaciones de \n",
    "    # la lista de features categóricos sin encodear\n",
    "    count1 = original.value_counts().to_frame()[0].values\n",
    "\n",
    "    # Recuento de cada una de las combinaciones de \n",
    "    # la lista de features categóricos ENCODEADOS\n",
    "    count2 = encoded.value_counts().to_frame()[0].values\n",
    "\n",
    "    # Comparación\n",
    "    print(\"El encoding fue realizado correctamente: \", np.equal(count1,count2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def BinaryEncoding(df,toEncode,verbose = False):\n",
    "    \n",
    "    print(\"Shape prev\",df[toEncode].shape)\n",
    "    \n",
    "    full_encoded,columns = encode_serie(df[toEncode[0]],toEncode[0])\n",
    "    for col in toEncode[1:]:\n",
    "        encoding,col_names = encode_serie(df[col],col)\n",
    "        full_encoded[col_names] = encoding\n",
    "        \n",
    "    if verbose: evaluate_encoding(df[toEncode],full_encoded)\n",
    "        \n",
    "    return full_encoded\n",
    "\"\"\"\n",
    "[]+[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El encoding fue realizado correctamente:  True\n",
      "El encoding fue realizado correctamente:  True\n"
     ]
    }
   ],
   "source": [
    "encoder = BinaryEncoding()\n",
    "trainEncoded = encoder.encode_DataFrame(trainset,toEncode,verbose=True)\n",
    "testEncoded = encoder.encode_DataFrame(testset,toEncode,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-encoded shape: (16947, 97)\n",
      "Train-encoded size: 1643859\n",
      "--------------------------------\n",
      "Test-encoded shape: (2551, 97)\n",
      "Test-encoded size: 247447\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train-encoded shape: {trainEncoded.shape}\")\n",
    "print(f\"Train-encoded size: {trainEncoded.size}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Test-encoded shape: {testEncoded.shape}\")\n",
    "print(f\"Test-encoded size: {testEncoded.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pudimos encodear las columnas categóricas reduciendo notablemente el espacio. El cálculo de columnas utilizadas previo valía con la suposición de que todas las features tenían la misma cantidad de valores. Pero aún no cumpliendose, la diferencia de columnas es poca con respecto al resultado obtenido con One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminamos este procesamiento de datos, para ver como un modelo de RandomForest se comporta frente a esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 13 features no categóricos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pricing, Delivery_Terms_Quote_Appr',\n",
       " 'Pricing, Delivery_Terms_Approved',\n",
       " 'Bureaucratic_Code_0_Approval',\n",
       " 'Bureaucratic_Code_0_Approved',\n",
       " 'Opportunity_ID',\n",
       " 'Sales_Contract_No',\n",
       " 'ASP',\n",
       " 'ASP_(converted)',\n",
       " 'Month',\n",
       " 'Delivery_Year',\n",
       " 'TRF',\n",
       " 'Total_Amount',\n",
       " 'Total_Taxable_Amount']"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cols = list()\n",
    "categorical_columns.append(\"target\")\n",
    "for col in trainset.columns.to_list():\n",
    "    if not col in categorical_columns and not col in date_columns:\n",
    "        final_cols.append(col)\n",
    "print(f\"Selected {len(final_cols)} features no categóricos\")\n",
    "final_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16947, 111)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTrain = trainset.loc[:,final_cols+[\"target\"]]\n",
    "finalTrain[trainEncoded.columns.to_list()] = trainEncoded\n",
    "finalTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2551, 110)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTest = testset.loc[:,final_cols]\n",
    "finalTest[testEncoded.columns.to_list()] = testEncoded\n",
    "finalTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminaron las columnas vacías o con valores iguales\n",
    "# Se rellenaron nan_values con promedios para features numéricos y con \"others\" para categóricos\n",
    "# Se eliminaron valores categóricos del set de test que no estan en el set de entrenamiento\n",
    "# Se realizó binary encoding para todos las features categóricas\n",
    "# Se agregó la columna \"target\" la cual tiene 1/0 según es \"Closed Won\" o no\n",
    "# Se eliminó la columna \"Stage\"\n",
    "\n",
    "path = \"datasets/\"\n",
    "name = \"first-rf-model\"\n",
    "finalTrain.to_csv(path+name+\"-train.csv\", index = False)\n",
    "finalTest.to_csv(path+name+\"-test.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
