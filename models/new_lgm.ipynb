{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "seed = 42\n",
    "import math\n",
    "\n",
    "import seaborn as sns # statistical data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../datasets/xgb-train.csv\")\n",
    "test = pd.read_csv(\"../datasets/xgb-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "test = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features totales: 116\n"
     ]
    }
   ],
   "source": [
    "target = \"target\"\n",
    "features = list(train.columns)\n",
    "features.remove(target)\n",
    "features.remove(\"Opportunity_ID\")\n",
    "\n",
    "#VANILLA NO\n",
    "# features.remove(\"delivery_delay\")\n",
    "# features.remove(\"opportunity_lifetime\")\n",
    "# features.remove(\"converted_taxable_amount\")\n",
    "# features.remove(\"last_modified_to_delivery\")\n",
    "# features.remove(\"currency_conversion_rate\")\n",
    "# features.remove(\"Occur\")\n",
    "# features.remove(\"delivery_window\")\n",
    "# features.remove(\"account_creation_to_created_opp\")\n",
    "\n",
    "#VANILLA SI\n",
    "features.remove('Total_Taxable_Amount')\n",
    "#features.remove('ASP_(converted)')\n",
    "features.remove(\"ASP\")\n",
    "features.remove(\"Total_Amount\")\n",
    "features.remove(\"Delivery_Year\")\n",
    "# features.remove(\"Week_Day\")\n",
    "\n",
    "#CONSIDERO REMOVIBLES\n",
    "# features.remove(\"created_blocknum\")   #FECHA!!\n",
    "features.remove(\"late_delivery_blocknum\")\n",
    "features.remove(\"early_delivery_blocknum\")\n",
    "features.remove(\"last_modified_blocknum\")\n",
    "features.remove(\"account_creation_blocknum\") #OJO CCON HIPOTESIS DEL CLIENTE VIEEJO\n",
    "print(\"Features totales: {}\".format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set de entrenamiento (size) (16947, 116)\n",
      "Set de testing (size) (2551, 116)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train.loc[:,features], train.loc[:,target]\n",
    "X_test_Opp = test.loc[:,\"Opportunity_ID\"]\n",
    "X_test = test.loc[:,features]\n",
    "\n",
    "print(\"Set de entrenamiento (size) {}\".format(X_train.shape))\n",
    "print(\"Set de testing (size) {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_80 = train[\"created_blocknum\"].describe()['75%']/0.945\n",
    "beta_test = train[train[\"created_blocknum\"]>percent_80]\n",
    "beta_train = train[train[\"created_blocknum\"]<percent_80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set de entrenamiento secundario (size) (14078, 116)\n",
      "Set de testing secundario (size) (2869, 116)\n"
     ]
    }
   ],
   "source": [
    "A_train, b_train = beta_train.loc[:,features], beta_train.loc[:,target]\n",
    "# A_test_Opp = beta_test.loc[:,\"Opportunity_ID\"]\n",
    "A_test, b_test = beta_test.loc[:,features], beta_test.loc[:,target]\n",
    "\n",
    "print(\"Set de entrenamiento secundario (size) {}\".format(A_train.shape))\n",
    "print(\"Set de testing secundario (size) {}\".format(A_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando nfolds=7,  num_boost_round=160  y  early_stopping_rounds=10\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "#----------------------------- C O N F I G U R A C I O N ----------------------------------\n",
    "#------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "nfolds = 7\n",
    "rounds = 160\n",
    "early_stopping_rounds = 10\n",
    "\n",
    "params = {\"objective\": \"binary\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'subsample': 1.0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 6,\n",
    "          'min_child_weight': 1,\n",
    "          'metric': \"binary_logloss\"\n",
    "          }\n",
    "beta_params = params.copy()\n",
    "beta_params['n_estimators'] = 100\n",
    "\n",
    "\n",
    "enaable_gridsearch_for_tree = True\n",
    "enaable_gridsearch_for_sampling = True\n",
    "enaable_gridsearch_for_learning = True\n",
    "final_cv = True\n",
    "enable_parcial_training = True\n",
    "\n",
    "print(\"Usando nfolds={},  num_boost_round={}\"\n",
    "      \"  y  early_stopping_rounds={}\".format(nfolds, rounds, early_stopping_rounds))\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIONES\n",
    "\n",
    "def find_best_param_tuple(lgb_train, params, param_tuple):\n",
    "    # Define initial best params and LogLoss\n",
    "    min_logloss = float(\"Inf\")\n",
    "    best_params = None\n",
    "    for param0, param1 in param_tuple['grid']:\n",
    "        print(\"CV with {}={}, {}={}\".format(param_tuple['names'][0],\n",
    "                                 param0,\n",
    "                                 param_tuple['names'][1],\n",
    "                                 param1))\n",
    "        # Update our parameters\n",
    "        params[param_tuple['names'][0]] = param0\n",
    "        if param_tuple['names'][1]: params[param_tuple['names'][1]] = param1\n",
    "        # Run CV\n",
    "        cv_results = lgb.cv(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            num_boost_round=rounds,\n",
    "            seed=1234,\n",
    "            nfold=nfolds,\n",
    "            metrics='logloss',\n",
    "            early_stopping_rounds=early_stopping_rounds\n",
    "        )\n",
    "        # Update best LogLoss\n",
    "        mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "        boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "        print(\"\\tLL {} for {} rounds\".format(mean_logloss, boost_rounds+1))\n",
    "        if mean_logloss < min_logloss:\n",
    "            min_logloss = mean_logloss\n",
    "            best_params = (param0, param1)\n",
    "    print(\"Best {},{}: {}, {}, LogLoss: {}\".format(param_tuple['names'][0],param_tuple['names'][1],best_params[0], best_params[1], min_logloss))\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuneo de: \n",
    "max_depth\n",
    "min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=20, min_child_weight=1\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8172, number of negative: 6354\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2383\n",
      "[LightGBM] [Info] Number of data points in the train set: 14526, number of used features: 112\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8171, number of negative: 6355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2383\n",
      "[LightGBM] [Info] Number of data points in the train set: 14526, number of used features: 112\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8171, number of negative: 6355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2383\n",
      "[LightGBM] [Info] Number of data points in the train set: 14526, number of used features: 112\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8171, number of negative: 6355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2383\n",
      "[LightGBM] [Info] Number of data points in the train set: 14526, number of used features: 112\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8171, number of negative: 6355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2383\n",
      "[LightGBM] [Info] Number of data points in the train set: 14526, number of used features: 112\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8171, number of negative: 6355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2383\n",
      "[LightGBM] [Info] Number of data points in the train set: 14526, number of used features: 112\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8171, number of negative: 6355\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2383\n",
      "[LightGBM] [Info] Number of data points in the train set: 14526, number of used features: 112\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562577 -> initscore=0.251629\n",
      "[LightGBM] [Info] Start training from score 0.251629\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562509 -> initscore=0.251349\n",
      "[LightGBM] [Info] Start training from score 0.251349\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562509 -> initscore=0.251349\n",
      "[LightGBM] [Info] Start training from score 0.251349\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562509 -> initscore=0.251349\n",
      "[LightGBM] [Info] Start training from score 0.251349\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562509 -> initscore=0.251349\n",
      "[LightGBM] [Info] Start training from score 0.251349\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562509 -> initscore=0.251349\n",
      "[LightGBM] [Info] Start training from score 0.251349\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.562509 -> initscore=0.251349\n",
      "[LightGBM] [Info] Start training from score 0.251349\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For early stopping, at least one dataset and eval metric is required for evaluation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-0900e4cbd32d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbest_tree_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_param_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_params_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_tree_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-de5cde8cb843>\u001b[0m in \u001b[0;36mfind_best_param_tuple\u001b[0;34m(lgb_train, params, param_tuple)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Run CV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         cv_results = lgb.cv(\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                 cb(callback.CallbackEnv(model=cvfolds,\n\u001b[0m\u001b[1;32m    600\u001b[0m                                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                                         \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/callback.py\u001b[0m in \u001b[0;36m_callback\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcmp_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/callback.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             raise ValueError('For early stopping, '\n\u001b[0m\u001b[1;32m    190\u001b[0m                              'at least one dataset and eval metric is required for evaluation')\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: For early stopping, at least one dataset and eval metric is required for evaluation"
     ]
    }
   ],
   "source": [
    "if enaable_gridsearch_for_tree:\n",
    "\n",
    "    tree_params_tuple = {\n",
    "        'names': ('max_depth', 'min_child_weight'),\n",
    "        'grid': [\n",
    "            (max_depth, min_child_weight)\n",
    "            for max_depth in range(20,26,1)\n",
    "            for min_child_weight in range(1,2)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    best_tree_params = find_best_param_tuple(lgb_train, params, tree_params_tuple)\n",
    "\n",
    "    params['max_depth'] = best_tree_params[0]\n",
    "    params['min_child_weight'] = best_tree_params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best max_depth,min_child_weight: 23, 1, LogLoss: 0.15631257142857144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enaable_gridsearch_for_sampling:\n",
    "\n",
    "    sample_params_tuple = {\n",
    "        'names': ('subsample', 'colsample_bytree'),\n",
    "        'grid': [\n",
    "            (subsample, colsample_bytree)\n",
    "            for subsample in [i/10. for i in range(8,11)]\n",
    "            for colsample_bytree in  [i/10. for i in range(3,5)]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    best_sample_params = find_best_param_tuple(lgb_train, params, sample_params_tuple)\n",
    "\n",
    "    params['subsample'] = best_sample_params[0]\n",
    "    params['colsample_bytree'] = best_sample_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, y_valid = train.loc[:,features], train.loc[:,target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = { \n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [16,32, 64], \n",
    "    'random_state' : [501],\n",
    "    'num_boost_round' : [3000],\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4], \n",
    "    }\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type = 'gbdt', \n",
    "                                   objective = 'binary',\n",
    "                                   n_estimators=175, \n",
    "                                   learning_rate =  0.1,\n",
    "                                   num_leaves =  31,\n",
    "                                   subsample = 1.0,\n",
    "                                   colsample_bytree = 0.3,\n",
    "                                   eval_metric  = 'logloss',\n",
    "                                   early_stopping_rounds=10)\n",
    "\n",
    "#g_lgbm = GridSearchCV(estimator=lgb_estimator, param_grid=gridParams, n_jobs = 3, cv= 3)\n",
    "\n",
    "lgb_model = lgb_estimator.fit(X=X_train, y=y_train, eval_set = (X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opportunity_ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10689</td>\n",
       "      <td>0.929982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10690</td>\n",
       "      <td>0.697446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10691</td>\n",
       "      <td>0.428577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10692</td>\n",
       "      <td>0.281747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10693</td>\n",
       "      <td>0.967341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>12364</td>\n",
       "      <td>0.985580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>12365</td>\n",
       "      <td>0.055137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>12366</td>\n",
       "      <td>0.027312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>12367</td>\n",
       "      <td>0.763994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>12368</td>\n",
       "      <td>0.018994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Opportunity_ID    Target\n",
       "0              10689  0.929982\n",
       "3              10690  0.697446\n",
       "8              10691  0.428577\n",
       "9              10692  0.281747\n",
       "15             10693  0.967341\n",
       "...              ...       ...\n",
       "2545           12364  0.985580\n",
       "2547           12365  0.055137\n",
       "2548           12366  0.027312\n",
       "2549           12367  0.763994\n",
       "2550           12368  0.018994\n",
       "\n",
       "[1567 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_submit_new = test[\"Opportunity_ID\"]\n",
    "pred = lgb_model.predict_proba(X_test)\n",
    "pred_df = pd.DataFrame(pred, columns=[\"Other\",\"Target\"])\n",
    "pred_df[\"Opportunity_ID\"] = ID_submit_new\n",
    "pred_df.drop(columns=\"Other\",inplace=True)\n",
    "pred_df = pred_df.drop_duplicates(\"Opportunity_ID\")\n",
    "pred_df[[\"Opportunity_ID\",\"Target\"]].to_csv(\"../submits/lgm_tunned_classifier.csv\",index=False)\n",
    "pred_df[[\"Opportunity_ID\",\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.994320\n",
       "1       0.990209\n",
       "2       0.669885\n",
       "3       0.829021\n",
       "4       0.998438\n",
       "          ...   \n",
       "1562    0.997522\n",
       "1563    0.932449\n",
       "1564    0.914969\n",
       "1565    0.978395\n",
       "1566    0.852016\n",
       "Name: Target, Length: 1567, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = pd.read_csv(\"../datasets/Y_TRUE.csv\")\n",
    "A = y_true[\"Target\"]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92998159, 0.8973892 , 0.93294381, ..., 0.0273117 , 0.76399373,\n",
       "       0.01899432])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = pred_df[\"Target\"].astype('float').values\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(round(A),B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set score: {:.4f}'.format(clf.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth': 8,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': 0, \n",
    "    'early_stopping_round': 1000}\n",
    "n_estimators=99999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(X_train.values, label=y_train.values)\n",
    "d_valid = lgb.Dataset(X_val.values, label=y_val.values)\n",
    "watchlist = [d_valid]\n",
    "reg = lgb.train(params, d_train, n_estimators, watchlist, verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = reg.predict(X_val.values)\n",
    "\n",
    "f = np.vectorize(math.exp)\n",
    "Y_pred = f(Y_pred)\n",
    "Y_val = f(y_val.values)\n",
    "mean_absolute_error(Y_val,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_predict = reg.predict(X_test)\n",
    "f = np.vectorize(math.exp)\n",
    "test_predict = f(test_predict)\n",
    "test_predict\n",
    "#escribir_respuesta(ids, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
