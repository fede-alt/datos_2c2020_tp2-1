{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword location                                               text  \\\n",
       "id                                                                          \n",
       "1         NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "4         NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "5         NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "6         NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "7         NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "...       ...      ...                                                ...   \n",
       "10869     NaN      NaN  Two giant cranes holding a bridge collapse int...   \n",
       "10870     NaN      NaN  @aria_ahrary @TheTawniest The out of control w...   \n",
       "10871     NaN      NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "10872     NaN      NaN  Police investigating after an e-bike collided ...   \n",
       "10873     NaN      NaN  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "       target  \n",
       "id             \n",
       "1           1  \n",
       "4           1  \n",
       "5           1  \n",
       "6           1  \n",
       "7           1  \n",
       "...       ...  \n",
       "10869       1  \n",
       "10870       1  \n",
       "10871       1  \n",
       "10872       1  \n",
       "10873       1  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"train.csv\")\n",
    "tweets.set_index(\"id\",inplace=True)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_largest_word(text):\n",
    "    \n",
    "    words = text.split(\" \")\n",
    "    largest = 0\n",
    "    for word in words:\n",
    "        if len(word) > largest:\n",
    "            largest = len(word)\n",
    "    \n",
    "    return largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_len_std(text):\n",
    "    \n",
    "    words = text.split(\" \")\n",
    "    lens = [ len(x) for x in words ]\n",
    "    if len(lens) is 1: return lens[0]\n",
    "    \n",
    "    # Calculo el promedio de las longitudes\n",
    "    mean = 0\n",
    "    for i in lens:\n",
    "        mean += i\n",
    "    mean /= len(lens)\n",
    "    \n",
    "    # Calculo el desvio estandar\n",
    "    std = 0\n",
    "    for i in lens:\n",
    "        std += (i-mean)*(i-mean)\n",
    "    std /= (len(lens)-1)\n",
    "    \n",
    "    return math.sqrt(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_len_mediana(text):\n",
    "    \n",
    "    words = text.split(\" \")\n",
    "    lens = [ len(x) for x in words ]\n",
    "    \n",
    "    total = len(lens)\n",
    "    if total is 1: return lens[0]\n",
    "    \n",
    "    mitad = int(total/2)\n",
    "    if total % 2 is 0:\n",
    "        return (lens[mitad-1]+lens[mitad])/2 \n",
    "    else:\n",
    "        return lens[mitad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hashtag(text):\n",
    "    count = 0\n",
    "    index = text.find(\"#\")\n",
    "    while not index is -1:\n",
    "        count += 1\n",
    "        index = text.find(\"#\",index+1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_arroba(text):\n",
    "    count = 0\n",
    "    index = text.find(\"@\")\n",
    "    while not index is -1:\n",
    "        count += 1\n",
    "        index = text.find(\"@\",index+1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_links(text):\n",
    "    count = 0\n",
    "    index = text.find(\"http\")\n",
    "    while not index is -1:\n",
    "        count += 1\n",
    "        index = text.find(\"http\",index+1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>words</th>\n",
       "      <th>len</th>\n",
       "      <th>largest_word</th>\n",
       "      <th>word_len_mean</th>\n",
       "      <th>word_len_std</th>\n",
       "      <th>word_len_med</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>5.307692</td>\n",
       "      <td>2.501282</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>1.397276</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>133</td>\n",
       "      <td>10</td>\n",
       "      <td>6.045455</td>\n",
       "      <td>2.723952</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.250817</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>22</td>\n",
       "      <td>7.545455</td>\n",
       "      <td>5.445599</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>12</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.373270</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>6.453128</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>137</td>\n",
       "      <td>13</td>\n",
       "      <td>7.210526</td>\n",
       "      <td>3.124137</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>7.230769</td>\n",
       "      <td>5.391113</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword location                                               text  \\\n",
       "id                                                                          \n",
       "1         NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "4         NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "5         NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "6         NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "7         NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "...       ...      ...                                                ...   \n",
       "10869     NaN      NaN  Two giant cranes holding a bridge collapse int...   \n",
       "10870     NaN      NaN  @aria_ahrary @TheTawniest The out of control w...   \n",
       "10871     NaN      NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "10872     NaN      NaN  Police investigating after an e-bike collided ...   \n",
       "10873     NaN      NaN  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "       target  words  len  largest_word  word_len_mean  word_len_std  \\\n",
       "id                                                                     \n",
       "1           1     13   69            11       5.307692      2.501282   \n",
       "4           1      7   38             6       5.428571      1.397276   \n",
       "5           1     22  133            10       6.045455      2.723952   \n",
       "6           1      8   65            10       8.125000      3.535534   \n",
       "7           1     16   88            10       5.500000      2.250817   \n",
       "...       ...    ...  ...           ...            ...           ...   \n",
       "10869       1     11   83            22       7.545455      5.445599   \n",
       "10870       1     20  125            12       6.250000      3.373270   \n",
       "10871       1      8   65            22       8.125000      6.453128   \n",
       "10872       1     19  137            13       7.210526      3.124137   \n",
       "10873       1     13   94            22       7.230769      5.391113   \n",
       "\n",
       "       word_len_med  \n",
       "id                   \n",
       "1               4.0  \n",
       "4               2.0  \n",
       "5               5.5  \n",
       "6              10.0  \n",
       "7               2.0  \n",
       "...             ...  \n",
       "10869           6.0  \n",
       "10870           7.0  \n",
       "10871           1.5  \n",
       "10872           2.0  \n",
       "10873           8.0  \n",
       "\n",
       "[7613 rows x 10 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering about text and word lenghts\n",
    "\n",
    "tweets[\"words\"] = tweets['text'].str.split().map(lambda x: len(x))\n",
    "tweets[\"len\"] = tweets['text'].str.len()\n",
    "tweets[\"largest_word\"] = tweets.agg({\"text\": len_largest_word})\n",
    "tweets[\"word_len_mean\"] = tweets[\"len\"]/tweets[\"words\"]\n",
    "tweets[\"word_len_std\"] = tweets.agg({\"text\": word_len_std})\n",
    "tweets[\"word_len_med\"] = tweets.agg({\"text\": word_len_mediana})\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>words</th>\n",
       "      <th>len</th>\n",
       "      <th>largest_word</th>\n",
       "      <th>word_len_mean</th>\n",
       "      <th>word_len_std</th>\n",
       "      <th>word_len_med</th>\n",
       "      <th>located</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>5.307692</td>\n",
       "      <td>2.501282</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>1.397276</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>133</td>\n",
       "      <td>10</td>\n",
       "      <td>6.045455</td>\n",
       "      <td>2.723952</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.250817</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>22</td>\n",
       "      <td>7.545455</td>\n",
       "      <td>5.445599</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>12</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.373270</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>6.453128</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>137</td>\n",
       "      <td>13</td>\n",
       "      <td>7.210526</td>\n",
       "      <td>3.124137</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>7.230769</td>\n",
       "      <td>5.391113</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword location                                               text  \\\n",
       "id                                                                          \n",
       "1         NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "4         NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "5         NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "6         NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "7         NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "...       ...      ...                                                ...   \n",
       "10869     NaN      NaN  Two giant cranes holding a bridge collapse int...   \n",
       "10870     NaN      NaN  @aria_ahrary @TheTawniest The out of control w...   \n",
       "10871     NaN      NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "10872     NaN      NaN  Police investigating after an e-bike collided ...   \n",
       "10873     NaN      NaN  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "       target  words  len  largest_word  word_len_mean  word_len_std  \\\n",
       "id                                                                     \n",
       "1           1     13   69            11       5.307692      2.501282   \n",
       "4           1      7   38             6       5.428571      1.397276   \n",
       "5           1     22  133            10       6.045455      2.723952   \n",
       "6           1      8   65            10       8.125000      3.535534   \n",
       "7           1     16   88            10       5.500000      2.250817   \n",
       "...       ...    ...  ...           ...            ...           ...   \n",
       "10869       1     11   83            22       7.545455      5.445599   \n",
       "10870       1     20  125            12       6.250000      3.373270   \n",
       "10871       1      8   65            22       8.125000      6.453128   \n",
       "10872       1     19  137            13       7.210526      3.124137   \n",
       "10873       1     13   94            22       7.230769      5.391113   \n",
       "\n",
       "       word_len_med  located  hashtags  mentions  links  \n",
       "id                                                       \n",
       "1               4.0        0         1         0      0  \n",
       "4               2.0        0         0         0      0  \n",
       "5               5.5        0         0         0      0  \n",
       "6              10.0        0         1         0      0  \n",
       "7               2.0        0         2         0      0  \n",
       "...             ...      ...       ...       ...    ...  \n",
       "10869           6.0        0         0         0      1  \n",
       "10870           7.0        0         0         2      0  \n",
       "10871           1.5        0         0         0      1  \n",
       "10872           2.0        0         0         0      0  \n",
       "10873           8.0        0         0         0      1  \n",
       "\n",
       "[7613 rows x 14 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweets[\"located\"] = (tweets[\"location\"] == tweets[\"location\"]).astype(int)\n",
    "tweets[\"hashtags\"] = tweets.agg({\"text\": count_hashtag})\n",
    "tweets[\"mentions\"] = tweets.agg({\"text\": count_arroba})\n",
    "tweets[\"links\"] = tweets.agg({\"text\": count_links})\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>words</th>\n",
       "      <th>len</th>\n",
       "      <th>largest_word</th>\n",
       "      <th>word_len_mean</th>\n",
       "      <th>word_len_std</th>\n",
       "      <th>word_len_med</th>\n",
       "      <th>located</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.903586</td>\n",
       "      <td>-32.037436</td>\n",
       "      <td>-6.306844</td>\n",
       "      <td>-1.746444</td>\n",
       "      <td>-1.989679</td>\n",
       "      <td>-1.176146</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.903586</td>\n",
       "      <td>-63.037436</td>\n",
       "      <td>-11.306844</td>\n",
       "      <td>-1.625565</td>\n",
       "      <td>-3.093684</td>\n",
       "      <td>-3.176146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.096414</td>\n",
       "      <td>31.962564</td>\n",
       "      <td>-7.306844</td>\n",
       "      <td>-1.008682</td>\n",
       "      <td>-1.767009</td>\n",
       "      <td>0.323854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.903586</td>\n",
       "      <td>-36.037436</td>\n",
       "      <td>-7.306844</td>\n",
       "      <td>1.070864</td>\n",
       "      <td>-0.955427</td>\n",
       "      <td>4.823854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.096414</td>\n",
       "      <td>-13.037436</td>\n",
       "      <td>-7.306844</td>\n",
       "      <td>-1.554136</td>\n",
       "      <td>-2.240144</td>\n",
       "      <td>-3.176146</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.903586</td>\n",
       "      <td>-18.037436</td>\n",
       "      <td>4.693156</td>\n",
       "      <td>0.491318</td>\n",
       "      <td>0.954638</td>\n",
       "      <td>0.823854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.096414</td>\n",
       "      <td>23.962564</td>\n",
       "      <td>-5.306844</td>\n",
       "      <td>-0.804136</td>\n",
       "      <td>-1.117691</td>\n",
       "      <td>1.823854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.903586</td>\n",
       "      <td>-36.037436</td>\n",
       "      <td>4.693156</td>\n",
       "      <td>1.070864</td>\n",
       "      <td>1.962167</td>\n",
       "      <td>-3.676146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.096414</td>\n",
       "      <td>35.962564</td>\n",
       "      <td>-4.306844</td>\n",
       "      <td>0.156390</td>\n",
       "      <td>-1.366823</td>\n",
       "      <td>-3.176146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.903586</td>\n",
       "      <td>-7.037436</td>\n",
       "      <td>4.693156</td>\n",
       "      <td>0.176633</td>\n",
       "      <td>0.900153</td>\n",
       "      <td>2.823854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword location                                               text  \\\n",
       "id                                                                          \n",
       "1         NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "4         NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "5         NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "6         NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "7         NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "...       ...      ...                                                ...   \n",
       "10869     NaN      NaN  Two giant cranes holding a bridge collapse int...   \n",
       "10870     NaN      NaN  @aria_ahrary @TheTawniest The out of control w...   \n",
       "10871     NaN      NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "10872     NaN      NaN  Police investigating after an e-bike collided ...   \n",
       "10873     NaN      NaN  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "       target     words        len  largest_word  word_len_mean  word_len_std  \\\n",
       "id                                                                              \n",
       "1           1 -1.903586 -32.037436     -6.306844      -1.746444     -1.989679   \n",
       "4           1 -7.903586 -63.037436    -11.306844      -1.625565     -3.093684   \n",
       "5           1  7.096414  31.962564     -7.306844      -1.008682     -1.767009   \n",
       "6           1 -6.903586 -36.037436     -7.306844       1.070864     -0.955427   \n",
       "7           1  1.096414 -13.037436     -7.306844      -1.554136     -2.240144   \n",
       "...       ...       ...        ...           ...            ...           ...   \n",
       "10869       1 -3.903586 -18.037436      4.693156       0.491318      0.954638   \n",
       "10870       1  5.096414  23.962564     -5.306844      -0.804136     -1.117691   \n",
       "10871       1 -6.903586 -36.037436      4.693156       1.070864      1.962167   \n",
       "10872       1  4.096414  35.962564     -4.306844       0.156390     -1.366823   \n",
       "10873       1 -1.903586  -7.037436      4.693156       0.176633      0.900153   \n",
       "\n",
       "       word_len_med  located  hashtags  mentions  links  \n",
       "id                                                       \n",
       "1         -1.176146        0         1         0      0  \n",
       "4         -3.176146        0         0         0      0  \n",
       "5          0.323854        0         0         0      0  \n",
       "6          4.823854        0         1         0      0  \n",
       "7         -3.176146        0         2         0      0  \n",
       "...             ...      ...       ...       ...    ...  \n",
       "10869      0.823854        0         0         0      1  \n",
       "10870      1.823854        0         0         2      0  \n",
       "10871     -3.676146        0         0         0      1  \n",
       "10872     -3.176146        0         0         0      0  \n",
       "10873      2.823854        0         0         0      1  \n",
       "\n",
       "[7613 rows x 14 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizamos los features\n",
    "\n",
    "columns_to_normalize = [\"words\",\"len\",\"largest_word\",\"word_len_mean\",\"word_len_std\",\"word_len_med\"]\n",
    "normalized_tweets = tweets.copy()\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    normalized_tweets[column] = normalized_tweets[column]-normalized_tweets[column].mean()\n",
    "    \n",
    "normalized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,InputLayer\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['len', 'largest_word', 'word_len_mean', 'word_len_std', 'word_len_med', 'located', 'hashtags', 'mentions', 'links']\n",
      "Label: target\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Preparamos el formato de los datos de entrada ##\n",
    "\n",
    "DATA_SIZE = normalized_tweets.shape[0]\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "dataset_df = normalized_tweets.reset_index().loc[:,[\"target\",\"words\",\"len\",\"largest_word\",\"word_len_mean\",\"word_len_std\",\"word_len_med\",\"located\",\"hashtags\",\"mentions\",\"links\"]]\n",
    "target = dataset_df.pop('target')\n",
    "\n",
    "# Definicion de los dataset TRAIN-TEST\n",
    "x_train, y_train = dataset_df.iloc[:int(DATA_SIZE*TRAIN_RATIO)].values, target.iloc[:int(DATA_SIZE*TRAIN_RATIO)].values\n",
    "x_test , y_test = dataset_df.iloc[int(DATA_SIZE*TRAIN_RATIO):].values, target.iloc[int(DATA_SIZE*TRAIN_RATIO):].values\n",
    "\n",
    "input_shape = (10,)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "features_names = list(dataset_df.columns)[1:]\n",
    "label_name = 'target'\n",
    "\n",
    "print(\"Features: {}\".format(features_names))\n",
    "print(\"Label: {}\".format(label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una funcion para que guarde un un archivo \"log.csv\" el accuracy obtenido\n",
    "# y los hyperparametros usados\n",
    "\n",
    "def logger(score,epochs,loss_func,optimizer,layers,batch_size):\n",
    "    \n",
    "    columns = [\"score\",\"epochs\", \"loss\" ,\"optimizer\",\"layers\"]\n",
    "\n",
    "    with open(\"log.csv\",\"r+\") as file:\n",
    "\n",
    "        file.read()\n",
    "        line = \"\"\n",
    "        line += str(score) + \",\" + str(epochs) + \",\" + loss_func[0] + \",\" +  optimizer[0] + \",\"\n",
    "\n",
    "        for layer in layers:\n",
    "\n",
    "            if layer[0] is \"dense\":\n",
    "                line += layer[0] +\"_\"+str(layer[1])+\"_\"+layer[2]\n",
    "            if layer[0] is \"dropout\":\n",
    "                line += layer[0] +\"_\"+str(layer[1])\n",
    "            line += \"#\"\n",
    "\n",
    "        line = line.rstrip(\"#\")\n",
    "        line += \",\"\n",
    "            \n",
    "        line += str(batch_size)\n",
    "        line += \"\\n\" \n",
    "        file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 400)               40400     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 500)               200500    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 733,312\n",
      "Trainable params: 733,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_batch_size = 20\n",
    "my_epochs = 50\n",
    "\n",
    "loss_func = [\"categorical_crossentropy\",keras.losses.categorical_crossentropy] \n",
    "\n",
    "#           [\"SGD\",keras.optimizers.SGD(learning_rate=0.01)]\n",
    "optimizer = [\"adam\",\"adam\"]\n",
    "\n",
    "# Layer = ( type , neurons , activation )\n",
    "layers = [(\"dense\",10,\"relu\"),\n",
    "          (\"dense\",100,\"relu\"),\n",
    "          (\"dense\",400,\"relu\"),\n",
    "          (\"dense\",500,\"relu\"),\n",
    "          (\"dropout\",0.3,\"relu\"),\n",
    "          (\"dense\",500,\"relu\"),\n",
    "          (\"dropout\",0.3,\"relu\"),\n",
    "          (\"dense\",400,\"relu\"),\n",
    "          (\"dense\",100,\"relu\"),\n",
    "          (\"dense\",2,\"softmax\"),\n",
    "         ]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "for layer in layers:\n",
    "    \n",
    "    if layer[0] is \"dense\":\n",
    "        model.add(Dense(layer[1], activation=layer[2]))\n",
    "    if layer[0] is \"dropout\":\n",
    "        model.add(Dropout(layer[1]))\n",
    "    \n",
    "\n",
    "model.compile(loss=loss_func[1],\n",
    "              optimizer=optimizer[1],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6090/6090 [==============================] - 8s 1ms/step - loss: 0.6721 - accuracy: 0.5913\n",
      "Epoch 2/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6502 - accuracy: 0.6079\n",
      "Epoch 3/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6446 - accuracy: 0.6273\n",
      "Epoch 4/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6441 - accuracy: 0.6291\n",
      "Epoch 5/50\n",
      "6090/6090 [==============================] - 6s 991us/step - loss: 0.6391 - accuracy: 0.6379\n",
      "Epoch 6/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6376 - accuracy: 0.6350\n",
      "Epoch 7/50\n",
      "6090/6090 [==============================] - 6s 989us/step - loss: 0.6356 - accuracy: 0.6402\n",
      "Epoch 8/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6341 - accuracy: 0.6463\n",
      "Epoch 9/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6323 - accuracy: 0.6402\n",
      "Epoch 10/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6323 - accuracy: 0.6496\n",
      "Epoch 11/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6308 - accuracy: 0.6430\n",
      "Epoch 12/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6303 - accuracy: 0.6496\n",
      "Epoch 13/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6285 - accuracy: 0.6470\n",
      "Epoch 14/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6249 - accuracy: 0.6489\n",
      "Epoch 15/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6228 - accuracy: 0.6498\n",
      "Epoch 16/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6223 - accuracy: 0.6496\n",
      "Epoch 17/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6188 - accuracy: 0.6553\n",
      "Epoch 18/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6187 - accuracy: 0.6575\n",
      "Epoch 19/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6161 - accuracy: 0.6632\n",
      "Epoch 20/50\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.6180 - accuracy: 0.6580\n",
      "Epoch 21/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6142 - accuracy: 0.6657\n",
      "Epoch 22/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6138 - accuracy: 0.6637\n",
      "Epoch 23/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6115 - accuracy: 0.6672\n",
      "Epoch 24/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6124 - accuracy: 0.6660\n",
      "Epoch 25/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6106 - accuracy: 0.6703\n",
      "Epoch 26/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6097 - accuracy: 0.6645\n",
      "Epoch 27/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6093 - accuracy: 0.6729\n",
      "Epoch 28/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6047 - accuracy: 0.6813\n",
      "Epoch 29/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6083 - accuracy: 0.6673\n",
      "Epoch 30/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6007 - accuracy: 0.6805\n",
      "Epoch 31/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.6014 - accuracy: 0.6810\n",
      "Epoch 32/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5972 - accuracy: 0.6831\n",
      "Epoch 33/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5980 - accuracy: 0.6854\n",
      "Epoch 34/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5947 - accuracy: 0.6785\n",
      "Epoch 35/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5899 - accuracy: 0.6872\n",
      "Epoch 36/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5872 - accuracy: 0.6834\n",
      "Epoch 37/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5851 - accuracy: 0.6920\n",
      "Epoch 38/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5852 - accuracy: 0.6908\n",
      "Epoch 39/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5797 - accuracy: 0.6936\n",
      "Epoch 40/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5815 - accuracy: 0.6956\n",
      "Epoch 41/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5783 - accuracy: 0.6962\n",
      "Epoch 42/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5734 - accuracy: 0.6993\n",
      "Epoch 43/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5766 - accuracy: 0.6979\n",
      "Epoch 44/50\n",
      "6090/6090 [==============================] - 8s 1ms/step - loss: 0.5724 - accuracy: 0.6952\n",
      "Epoch 45/50\n",
      "6090/6090 [==============================] - 8s 1ms/step - loss: 0.5696 - accuracy: 0.7038\n",
      "Epoch 46/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5646 - accuracy: 0.7102\n",
      "Epoch 47/50\n",
      "6090/6090 [==============================] - 8s 1ms/step - loss: 0.5647 - accuracy: 0.7085\n",
      "Epoch 48/50\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.5649 - accuracy: 0.7089\n",
      "Epoch 49/50\n",
      "6090/6090 [==============================] - 8s 1ms/step - loss: 0.5626 - accuracy: 0.7107\n",
      "Epoch 50/50\n",
      "6090/6090 [==============================] - 8s 1ms/step - loss: 0.5589 - accuracy: 0.7120\n",
      "Test loss: 0.7728811467233959\n",
      "Test accuracy: 0.6605384349822998\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo\n",
    "model.fit(x_train, y_train, batch_size=my_batch_size, epochs=my_epochs)\n",
    "\n",
    "# Lo evaluamos en el set de validacion\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Registramos el resultado\n",
    "logger(round(score[1],3),my_epochs,loss_func,optimizer,layers,my_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta clase fue hecha con la intencion de hacer un Gird Search automatico pero la cantidad de\n",
    "# combinaciones que se pueden introducir hace que el tiempo crezca exponencialmente.\n",
    "\n",
    "# Despues de varias puebas y no ver mejoras asumimos que quizas los modelos que construye \n",
    "# no son eficaces.\n",
    "\n",
    "\n",
    "class HyperParametrizador:\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Hparam = { \"epochs\" : { \"values\" : [1,2,3],\n",
    "                            \"reg\" : [ ]   },\n",
    "            \"activation\": {\"values\": [4,5,6],\n",
    "                            \"reg\": [ ]    },\n",
    "              \"layers\":  { \"values\" : [7,8],\n",
    "                            \"reg\" : [ ]   },\n",
    "            \"neurons\":  { \"values\" : [9,10 ], \n",
    "                            \"reg\" : [ ]    },\n",
    "            \"loss\":  { \"values\" : [11,12], \n",
    "                            \"reg\" : [ ]    },\n",
    "            \"dropout\": {\"values\" : [13], \n",
    "                         \"reg\" : [ ]       },\n",
    "            \"optimizer\": {\"values\" : [ ], \n",
    "                         \"reg\" : [ ]}\n",
    "             }\n",
    "    \"\"\"\n",
    "    class_param = {}\n",
    "    \n",
    "    def __init__(self,features,targets,shape):\n",
    "        \n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.model = None\n",
    "        self.input_shape = shape\n",
    "        self.hparam = {}\n",
    "        self.layers_count = 1\n",
    "    \n",
    "    # Genera una lista con todas las combinaciones de neuronas-activacion\n",
    "    # que puede tener una capa\n",
    "    def generate_layers(self):\n",
    "        \n",
    "        layers = []\n",
    "        actual = [None,None]\n",
    "        for neuron in self.hparam[\"neurons\"][\"values\"]:\n",
    "            actual[0] = neuron\n",
    "            for activation in self.hparam[\"activation\"][\"values\"]:\n",
    "                actual[1] = activation\n",
    "                layers.append(tuple(actual))\n",
    "                \n",
    "        return layers\n",
    "        \n",
    "    # Preprocesa el formato de las capas para generar el modelo con \"generate_NN_model\"\n",
    "    def collect_layers(self,selected_params):\n",
    "        \n",
    "        print(\"Collecting layers..\")\n",
    "        # Para mayor practicidad, la red es una lista de tuplas donde cada tupla es una capa\n",
    "        # con sus neuronas y funcion de activacion\n",
    "        network = []\n",
    "        for i in range(self.layers_count):\n",
    "            network.append(selected_params[\"layer\"+str(i)])\n",
    "        return network\n",
    "            \n",
    "    # Genera un modelo secuencial con los hyperparametros especificados \n",
    "    def generate_NN_model(self,network,loss_func,optimizer_func):\n",
    "        \n",
    "        print(\"Generating model..\")\n",
    "        self.model = Sequential()\n",
    "        self.model.add(InputLayer(input_shape=self.input_shape))\n",
    "        \n",
    "        for layer in network:\n",
    "            neurons,funct = layer[0],self.class_param[layer[1]]\n",
    "            self.model.add(Dense(neurons,activation=funct))\n",
    "        \n",
    "        self.model.add(Dense(2,activation= self.class_param[\"softmax\"]))\n",
    "        self.model.compile(loss=loss_func,\n",
    "              optimizer=optimizer_func,\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "        #self.show_summary()\n",
    "        \n",
    "        self.saved_init_weights = self.model.get_weights()\n",
    "\n",
    "    def show_summary(self):\n",
    "        self.model.summary()\n",
    "        \n",
    "    # \n",
    "    #  K-FOLD CROSS VALIDATION\n",
    "    #\n",
    "    def kF_crossValidation(self,k_folds,epochs):\n",
    "        \n",
    "        DATA_SIZE =len(self.features)\n",
    "        total_subsets = int(DATA_SIZE/k_folds)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i in range(total_subsets):\n",
    "            #print(\"K-Fold Cross Validation progress: {}/{}..\".format(i+1,total_subsets),end=\"\")\n",
    "            \n",
    "            from_fold = k_folds*i\n",
    "            to_fold = k_folds*(i+1)\n",
    "        \n",
    "            # Concateno la primera mitad (A) antes del fold de validacion con la segunda (B) despues del fold de validacion\n",
    "            xA_subset,yA_subset = self.features[ :from_fold], self.targets[ :from_fold]\n",
    "            xB_subset,yB_subset = self.features[to_fold: ]  , self.targets[to_fold: ]\n",
    "            x_train,y_train = np.concatenate((xA_subset, xB_subset)) , np.concatenate((yA_subset, yB_subset))\n",
    "            \n",
    "            # Validation set (el fold actual)\n",
    "            x_test,y_test = self.features[from_fold:to_fold] , self.targets[from_fold:to_fold]\n",
    "\n",
    "            #print(\"training.. \",end=\"\")\n",
    "            #print(\"total_data: {} | k: {}\".format(DATA_SIZE,k_folds))\n",
    "            self.train(x_train,y_train,epochs)\n",
    "            \n",
    "            #print(\"validating.. \",end=\"\")\n",
    "            metrics = self.model.evaluate(x_test, y_test, verbose = 0)\n",
    "            #print(\"Local loss/score: {} - {}\".format(round(metrics[0],3),round(metrics[1],3)))\n",
    "            results.append((round(metrics[0],3),round(metrics[1],3)))\n",
    "            \n",
    "            # Reset the weights\n",
    "            self.model.set_weights(self.saved_init_weights)\n",
    "            \n",
    "        score = (0,0)\n",
    "        for local_score in results:\n",
    "            score = ( score[0] + local_score[0] , score[1] + local_score[1] )\n",
    "        \n",
    "        score = (score[0]/len(results) , score[1]/len(results))\n",
    "        \n",
    "        print(\"Finished validation with score => loss: {} - accuracy: {}\".format(score[0],score[1]))\n",
    "        \n",
    "        return score       \n",
    "        \n",
    "                      \n",
    "    def train(self,x_train,y_train,ammount_epochs):\n",
    "        self.model.fit(x_train, y_train, batch_size=300, epochs=ammount_epochs, verbose = 0)\n",
    "            \n",
    "            \n",
    "    # Devuelve el resultado de un modelo en el archivo \"log.csv\"\n",
    "    def log(self,parameters,score):\n",
    "        \n",
    "        columns = [\"score\",\"epochs\", \"loss\" ,\"optimizer\",\"layers\"]\n",
    "\n",
    "        with open(\"log.csv\",\"r+\") as file:\n",
    "            \n",
    "            file.read()\n",
    "            line = \"\"\n",
    "            for column in columns:\n",
    "                \n",
    "                # El resultado final de esta combinacion de hyperparametros\n",
    "                if column is \"score\":\n",
    "                    line += str(round(score,3))\n",
    "                \n",
    "                # Las capas usadas\n",
    "                elif column is \"layers\":\n",
    "                    for i in range(self.layers_count):\n",
    "                        for layer_data in parameters[\"layer\"+str(i)]:\n",
    "                            line +=  str(layer_data) + \"_\"\n",
    "                        line = line.rstrip(\"_\")\n",
    "                        line += \"#\"\n",
    "                    line = line.rstrip(\"#\")\n",
    "                \n",
    "                # Los hyperparametros independientes\n",
    "                else:\n",
    "                    line += str(parameters[column])\n",
    "                \n",
    "                line += \",\"\n",
    "            \n",
    "            line = line.rstrip(\",\")\n",
    "            line += \"\\n\" \n",
    "            file.write(line)    \n",
    "    \n",
    "                      \n",
    "    def test_parameters(self,parameters):\n",
    "        \n",
    "        # k to k-Fold CrossValidation #\n",
    "        k = 700   \n",
    "        network = self.collect_layers(parameters)\n",
    "        self.generate_CNN_model(network,parameters[\"loss\"],parameters[\"optimizer\"])\n",
    "        score = self.kF_crossValidation(k,parameters[\"epochs\"])        \n",
    "        \n",
    "        self.log(parameters,score[1])\n",
    "        \n",
    "        # Regular probabilidades (?)\n",
    "\n",
    "        return score\n",
    "    \n",
    "                      \n",
    "    # Agrega valores a la grilla de Hyperparametros \n",
    "    def addHyperParam(self,hyperparam, value):\n",
    "        \n",
    "        if type(value) is type(list()):\n",
    "            for x in value:\n",
    "                self.addHyperParam(hyperparam,x) \n",
    "            return\n",
    "            \n",
    "        print(\"Se agrega un valor a una categoria: {} -> {}\".format(value,hyperparam))\n",
    "        \n",
    "    \n",
    "        if hyperparam in self.hparam:\n",
    "            #print(\"Categoria existente, añidiendo..\")\n",
    "            self.hparam[hyperparam][\"values\"].append(value)\n",
    "        else:\n",
    "            #print(\"Categoria NO existente, agregando una nueva..\")\n",
    "            new_category = {\"values\":[value],\n",
    "                           \"reg\":[]}\n",
    "            self.hparam[hyperparam] = new_category\n",
    "    \n",
    "                      \n",
    "    # Ascocia un nombre a un una instancia de un hyperparametro para poder ser usado como valor\n",
    "    def addClassParam(self,name,classParam):\n",
    "        \n",
    "        self.class_param[name] = classParam                      \n",
    "    \n",
    "    \n",
    "    # Funcion recursiva que recorre todas las combinacioens de hyperparametros\n",
    "    #\n",
    "    # free_param => Lista de aquellos hyperparametros que no tienen un valor asignado\n",
    "    # selected_param => Diccionario con los hyperparametros como claves y su valor asignado como valor.\n",
    "    def rec_gird_search(self,free_params,selected_param):\n",
    "        \n",
    "        if len(free_params) <= 0:\n",
    "            print(\"eRROR\")\n",
    "            return\n",
    "                      \n",
    "        if len(free_params) is 1:\n",
    "            \n",
    "            token = free_params[0]\n",
    "            for value in self.hparam[token][\"values\"]:\n",
    "                selected_param[token] = value\n",
    "                \n",
    "                # Se prueba el modelo con los parametros tomados\n",
    "                self.test_parameters(selected_param)\n",
    "            return\n",
    "\n",
    "        token = free_params.pop(0)\n",
    "        for value in self.hparam[token][\"values\"]:\n",
    "            selected_param[token] = value\n",
    "            self.rec_gird_search(free_params,selected_param)\n",
    "        \n",
    "        free_params.insert(0,token)\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    # Selecciona el numero de capas a usar\n",
    "    def set_layers(self, number):\n",
    "        self.layers_count = number\n",
    "\n",
    "        \n",
    "    def start(self):\n",
    "        \n",
    "        layers_combinations = self.generate_layers()\n",
    "        total_comb = len(layers_combinations)\n",
    "        \n",
    "        # Seteo las combinaciones para las capas \n",
    "        for i in range(self.layers_count):\n",
    "            self.hparam[\"layer\"+str(i)] = {\"values\":layers_combinations}\n",
    "        \n",
    "        print(\"Starting GirdSearch..\")\n",
    "        free_params = list(self.hparam.keys())\n",
    "        selected_param = {}\n",
    "        self.rec_gird_search(free_params,selected_param)\n",
    "        \n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = normalized_tweets.reset_index().loc[:,[\"target\",\"words\",\"len\",\"largest_word\",\"word_len_mean\",\"word_len_std\",\"word_len_med\",\"located\",\"hashtags\",\"mentions\",\"links\"]]\n",
    "targets = features.pop('target')\n",
    "\n",
    "targets_reshaped = keras.utils.to_categorical(targets.values, 2)\n",
    "\n",
    "hyperclass = HyperParametrizador(features.values,targets_reshaped,(10,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se agrega un valor a una categoria: 2 -> epochs\n",
      "Categoria NO existente, agregando una nueva..\n",
      "Se agrega un valor a una categoria: relu -> activation\n",
      "Categoria NO existente, agregando una nueva..\n",
      "Se agrega un valor a una categoria: 2 -> neurons\n",
      "Categoria NO existente, agregando una nueva..\n",
      "Se agrega un valor a una categoria: 10 -> neurons\n",
      "Categoria existente, añidiendo..\n",
      "Se agrega un valor a una categoria: 50 -> neurons\n",
      "Categoria existente, añidiendo..\n",
      "Se agrega un valor a una categoria: 200 -> neurons\n",
      "Categoria existente, añidiendo..\n",
      "Se agrega un valor a una categoria: SGD -> optimizer\n",
      "Categoria NO existente, agregando una nueva..\n",
      "Se agrega un valor a una categoria: categorical_crossentropy -> loss\n",
      "Categoria NO existente, agregando una nueva..\n"
     ]
    }
   ],
   "source": [
    "# Set-Up de los hyperparametros a probar\n",
    "\n",
    "hyperclass.set_layers(4)\n",
    "hyperclass.addHyperParam(\"epochs\",2)\n",
    "\n",
    "hyperclass.addClassParam(\"softmax\",activations.softmax)\n",
    "hyperclass.addClassParam(\"relu\",activations.relu)\n",
    "hyperclass.addHyperParam(\"activation\",\"relu\")\n",
    "hyperclass.addHyperParam(\"neurons\",[2,10,50,200])\n",
    "\n",
    "hyperclass.addClassParam(\"SGD\",keras.optimizers.SGD(learning_rate=0.05))\n",
    "hyperclass.addHyperParam(\"optimizer\",\"SGD\")\n",
    "\n",
    "hyperclass.addClassParam(\"categorical_crossentropy\",keras.losses.categorical_crossentropy)\n",
    "hyperclass.addHyperParam(\"loss\",\"categorical_crossentropy\")\n",
    "\n",
    "\n",
    "network = [(10,\"relu\"),(25,\"relu\"),(2,\"softmax\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': {'values': [2], 'reg': []},\n",
       " 'activation': {'values': ['relu'], 'reg': []},\n",
       " 'neurons': {'values': [2, 10, 50, 200], 'reg': []},\n",
       " 'optimizer': {'values': ['SGD'], 'reg': []},\n",
       " 'loss': {'values': ['categorical_crossentropy'], 'reg': []}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperclass.hparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GirdSearch..\n",
      "Collecting layers..\n",
      "Generating model..\n",
      "Finished validation with score => loss: 0.6891 - accuracy: 0.5789\n",
      "Collecting layers..\n",
      "Generating model..\n",
      "Finished validation with score => loss: 0.6674 - accuracy: 0.5789\n",
      "Collecting layers..\n",
      "Generating model..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-8246f8992555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyperclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mfree_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mselected_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mselected_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_gird_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mfree_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mrec_gird_search\u001b[0;34m(self, free_params, selected_param)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# Se prueba el modelo con los parametros tomados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mtest_parameters\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_CNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkF_crossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-ee960317602d>\u001b[0m in \u001b[0;36mkF_crossValidation\u001b[0;34m(self, k_folds, epochs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m#print(\"validating.. \",end=\"\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;31m#print(\"Local loss/score: {} - {}\".format(round(metrics[0],3),round(metrics[1],3)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1359\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m                                          \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m                                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hyperclass.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
